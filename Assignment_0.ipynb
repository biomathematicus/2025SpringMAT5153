{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biomathematicus/2025SpringMAT5153/blob/main/Assignment_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ok-TLLmTFwm"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# create a python dictionary of stock symbols and text names.\n",
        "symbol_dict = {\n",
        "    \"TOT\": \"Total\",\n",
        "    \"XOM\": \"Exxon\",\n",
        "    \"CVX\": \"Chevron\",\n",
        "    \"COP\": \"ConocoPhillips\",\n",
        "    \"VLO\": \"Valero Energy\",\n",
        "   }\n",
        "# \"decompose\" the dictionary for ease of work - two arrays.\n",
        "symbols, names = np.array(sorted(symbol_dict.items())).T\n",
        "# empty list\n",
        "quotes = []\n",
        "#\n",
        "################### To fetch individual CSV files from the internet\n",
        "# for symbol in symbols:\n",
        "#     print(\"Fetching quote history for %r\" % symbol, file=sys.stderr)\n",
        "#     url = (\n",
        "#         \"https://raw.githubusercontent.com/scikit-learn/examples-data/\"\n",
        "#         \"master/financial-data/{}.csv\"\n",
        "#     )\n",
        "#     quotes.append(pd.read_csv(url.format(symbol)))\n",
        "#\n",
        "#################### To fetch individual CSV files from local folder\n",
        "# for symbol in symbols:\n",
        "#     print(\"Fetching quote history for %r\" % symbol, file=sys.stderr)\n",
        "#     direct = \"examples-data-master/financial-data/{}.csv\"\n",
        "#     quotes.append(pd.read_csv(direct.format(symbol)))\n",
        "####################\n",
        "# close_prices = np.vstack([q[\"close\"] for q in quotes])\n",
        "# open_prices = np.vstack([q[\"open\"] for q in quotes])\n",
        "# # The daily variations of the quotes are what carry the most information\n",
        "# variation = close_prices - open_prices\n",
        "#################### To merge separate CSV files into 1 and write to disk\n",
        "# data1 = pd.DataFrame(variation[0],columns=[symbols[0]])\n",
        "# merged_df = data1\n",
        "# for k in range(1,N):\n",
        "#     ToBe_merged = pd.DataFrame(variation[k],columns=[symbols[k]])\n",
        "#     merged_df = merged_df.merge(ToBe_merged,left_index=True,right_index=True)\n",
        "# merged_df.to_csv('StockVar_Data.csv',index=False)\n",
        "####################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a4gVPD-TFwp"
      },
      "outputs": [],
      "source": [
        "# The CSV file has column headers that are stock symbols. Natural given\n",
        "# how the original separate CSV files were merged into one. Pandas can\n",
        "# easily extract rows or columns; mathematically it is simple a transpose.\n",
        "# HOWEVER, the scikit-learn routines used for clustering later,\n",
        "# REQUIRE a specific form or they will \"HANG\". They expect ROW headers\n",
        "# to be the stock symbols.\n",
        "# Method 1: read in CSV took the transpose.\n",
        "df = pd.read_csv('StockVar_Data.csv')\n",
        "variation = np.array(df)\n",
        "variation = variation.T\n",
        "variation.shape\n",
        "###############\n",
        "# Method 2: read in CSV as above & use Pandas to take transpose dataframe, then\n",
        "# write it out as CSV file. This causes own set of issues: column 0\n",
        "# is now the Stock symbols and you must drop those. Here is the code.\n",
        "#\n",
        "# df_transpose = df.transpose()\n",
        "# df_transpose.to_csv('StockVar_Data_Adj.csv')\n",
        "#\n",
        "# df = pd.read_csv('StockVar_Data_Adj.csv')\n",
        "# # Convert the dataframe into a numpy array.\n",
        "# df_filtered = df.iloc[:,1:]\n",
        "# variation = np.array(df_filtered)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-edvcCATFwq"
      },
      "outputs": [],
      "source": [
        "from sklearn import covariance\n",
        "\n",
        "alphas = np.logspace(-1.5, 1, num=10)\n",
        "edge_model = covariance.GraphicalLassoCV(alphas=alphas)\n",
        "\n",
        "# standardize the time series: using correlations rather than covariance\n",
        "# former is more efficient for structure recovery\n",
        "X = variation.copy().T\n",
        "X /= X.std(axis=0)\n",
        "edge_model.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnK6hjpDTFwq"
      },
      "outputs": [],
      "source": [
        "from sklearn import cluster\n",
        "\n",
        "_, labels = cluster.affinity_propagation(edge_model.covariance_, random_state=0)\n",
        "n_labels = labels.max()\n",
        "\n",
        "for i in range(n_labels + 1):\n",
        "    print(f\"Cluster {i + 1}: {', '.join(names[labels == i])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qICyPNTQTFwq"
      },
      "outputs": [],
      "source": [
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP5gIPr6TFwr"
      },
      "outputs": [],
      "source": [
        "from sklearn import manifold\n",
        "\n",
        "node_position_model = manifold.LocallyLinearEmbedding(\n",
        "    n_components=2, eigen_solver=\"dense\", n_neighbors=6\n",
        ")\n",
        "\n",
        "embedding = node_position_model.fit_transform(X.T).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exrPxfIhTFwr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "\n",
        "plt.figure(1, facecolor=\"w\", figsize=(10, 8))\n",
        "plt.clf()\n",
        "ax = plt.axes([0.0, 0.0, 1.0, 1.0])\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Plot the graph of partial correlations\n",
        "partial_correlations = edge_model.precision_.copy()\n",
        "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
        "partial_correlations *= d\n",
        "partial_correlations *= d[:, np.newaxis]\n",
        "non_zero = np.abs(np.triu(partial_correlations, k=1)) > 0.02\n",
        "\n",
        "# Plot the nodes using the coordinates of our embedding\n",
        "plt.scatter(\n",
        "    embedding[0], embedding[1], s=100 * d**2, c=labels, cmap=plt.cm.nipy_spectral\n",
        ")\n",
        "\n",
        "# Plot the edges\n",
        "start_idx, end_idx = np.where(non_zero)\n",
        "# a sequence of (*line0*, *line1*, *line2*), where::\n",
        "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
        "segments = [\n",
        "    [embedding[:, start], embedding[:, stop]] for start, stop in zip(start_idx, end_idx)\n",
        "]\n",
        "values = np.abs(partial_correlations[non_zero])\n",
        "lc = LineCollection(\n",
        "    segments, zorder=0, cmap=plt.cm.hot_r, norm=plt.Normalize(0, 0.7 * values.max())\n",
        ")\n",
        "lc.set_array(values)\n",
        "lc.set_linewidths(15 * values)\n",
        "ax.add_collection(lc)\n",
        "\n",
        "# Add a label to each node. The challenge here is that we want to\n",
        "# position the labels to avoid overlap with other labels\n",
        "for index, (name, label, (x, y)) in enumerate(zip(names, labels, embedding.T)):\n",
        "    dx = x - embedding[0]\n",
        "    dx[index] = 1\n",
        "    dy = y - embedding[1]\n",
        "    dy[index] = 1\n",
        "    this_dx = dx[np.argmin(np.abs(dy))]\n",
        "    this_dy = dy[np.argmin(np.abs(dx))]\n",
        "    if this_dx > 0:\n",
        "        horizontalalignment = \"left\"\n",
        "        x = x + 0.002\n",
        "    else:\n",
        "        horizontalalignment = \"right\"\n",
        "        x = x - 0.002\n",
        "    if this_dy > 0:\n",
        "        verticalalignment = \"bottom\"\n",
        "        y = y + 0.002\n",
        "    else:\n",
        "        verticalalignment = \"top\"\n",
        "        y = y - 0.002\n",
        "    plt.text(\n",
        "        x,\n",
        "        y,\n",
        "        name,\n",
        "        size=10,\n",
        "        horizontalalignment=horizontalalignment,\n",
        "        verticalalignment=verticalalignment,\n",
        "        bbox=dict(\n",
        "            facecolor=\"w\",\n",
        "            edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
        "            alpha=0.6,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "plt.xlim(\n",
        "    embedding[0].min() - 0.15 * np.ptp(embedding[0]),\n",
        "    embedding[0].max() + 0.10 * np.ptp(embedding[0]),\n",
        ")\n",
        "plt.ylim(\n",
        "    embedding[1].min() - 0.03 * np.ptp(embedding[1]),\n",
        "    embedding[1].max() + 0.03 * np.ptp(embedding[1]),\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DRgaB08TFwr"
      },
      "outputs": [],
      "source": [
        "# Extract appropriate columns from original dataframe\n",
        "my_names = ['Total', 'Exxon', 'Chevron', 'ConocoPhillips', 'Valero Energy']\n",
        "my_symbols = []\n",
        "# for key,value in symbol_dict.items():\n",
        "#     print(f\"{key}: {value}\")\n",
        "for j in range(len(names)):\n",
        "    if names[j] in my_names:\n",
        "        my_symbols.append(symbols[j])\n",
        "print(my_symbols)\n",
        "\n",
        "dfmy = df[my_symbols]\n",
        "dfmy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCLG1K0HTFwr"
      },
      "outputs": [],
      "source": [
        "dfmy.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9HXiZmlTFwr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for more refinement use matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "f = dfmy['TOT']\n",
        "plt.plot(f)\n",
        "# Now check out the plot examples on the https://matplotlib.org/ webpages.\n",
        "# Being able to present strong visualizations of your results at\n",
        "# conferences and in articles/reports is essential."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "f = dfmy['XOM']\n",
        "plt.plot(f)"
      ],
      "metadata": {
        "id": "MDESvLl3TcDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "f = dfmy['CVX']\n",
        "plt.plot(f)"
      ],
      "metadata": {
        "id": "JP584yDMTfX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "f = dfmy['COP']\n",
        "plt.plot(f)"
      ],
      "metadata": {
        "id": "mNVr2EK3Tg-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matpltlib import pyplot as plt\n",
        "f = dfmy['VLO']\n",
        "plt.plot(f)"
      ],
      "metadata": {
        "id": "IZ4b63RJTjWV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}